% java, snippet

# Count duplicate using Stream API.
items.stream()
     .map(Item::getId)
     .collect(Collectors.groupingBy(Function.identity(), Collectors.counting()))
     .values()
     .stream()
     .filter(x -> x > 1)
     .count();

# Check which Garbage collector is used.
; https://stackoverflow.com/a/5175321/3612053
List<GarbageCollectorMXBean> l = ManagementFactory.getGarbageCollectorMXBeans();
for(GarbageCollectorMXBean b : l) {
    System.out.println(b.getName());
}

# Kafka consumer.
@Slf4j
@RequiredArgsConstructor
public class KafkaMessageProcessor implements Runnable, AutoCloseable {

    private final List<String> topics;
    private final Duration pollDuration;
    private final KafkaConsumer<String, String> kafkaConsumer;
    private final Consumer<String> processMessage;

    private AtomicBoolean shutdown = new AtomicBoolean();
    private CountDownLatch shutdownLatch = new CountDownLatch(1);

    public static void main(String[] args) throws InterruptedException {
        var consumerProperties = new Properties();
        consumerProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        consumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
        consumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        consumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");
        List<String> consumedMessages = new ArrayList<>();

        try (var kafkaMessageProcessor = new KafkaLiveStreamProcessor(
                List.of("topic"),
                Duration.ofMillis(100),
                new KafkaConsumer<>(consumerProperties, new StringDeserializer(), new StringDeserializer()),
                consumedMessages::add
        )) {
            CompletableFuture.runAsync(kafkaMessageProcessor);
            Thread.sleep(1000);
        }
    }

    @Override
    public void run() {
        kafkaConsumer.subscribe(topics);

        try {
            process();
        } finally {
            // Closing the kafka consumer here because the consumer is not thread-safe, so we need to ensure the kafka
            // consumer is closed using the same thread.
            kafkaConsumer.close();
            LOGGER.info("Kafka consumer closed");
            shutdownLatch.countDown();
        }
    }

    @Override
    public void close() {
        shutdown.set(true);
        try {
            shutdownLatch.await();
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            LOGGER.error("Thread was interrupted while waiting for the shutdown latch", e);
        }
    }

    private void process() {
        while (!shutdown.get()) {
            pollMessages().forEach(processMessage::accept);
            kafkaConsumer.commitAsync();
        }
    }

    private Stream<String> pollMessages() {
        ConsumerRecords<String, String> messages = kafkaConsumer.poll(pollDuration);
        return StreamSupport.stream(messages.spliterator(), false)
                .map(ConsumerRecord::value);
    }
}

% java, io, snippet
; src: https://dev.java/learn/modernio/

# Read file line by line with Scanner
try (var scanner = new Scanner(new File("filename.txt"))) {
    while (scanner.hasNextLine()) {
        String nextLine = scanner.nextLine();
    }
}

# Read text file into a String.
String content = Files.readString(Path.of("/path/to/file.txt"));

# Read all lines.
List<String> lines = Files.readAllLines(Path.of("/path/to/file.txt"));

# Read all lines from large file.
try (Stream<String> lines = Files.lines(Path.of("/path/to/file.txt")) {
}

# Read words separated by non-letters.
Stream<String> tokens = new Scanner(path).useDelimiter("\\PL+").tokens();

# Write String to file.
Files.writeString(Path.of("/path/to/file.txt"), content);

# Write list of lines to file.
List<String> lines = List.of("line1", "line2", "line3");
Files.write(path, lines);

# Write to file with printf.
var writer = new PrintWriter(path.toFile());
writer.printf(locale, "Hello, %s, next year you'll be %d years old!%n", name, age + 1);

# Delete a file or folder in Java.
private void deleteFile(Path path) {
    try {
        if (Files.exists(path)) {
            if (Files.isDirectory(path)) {
                deleteFolder(path);
            } else if (Files.deleteIfExists(path)) {
                LOGGER.debug("File deleted: {}", path);
            }
        } else {
            LOGGER.info("File does not exist => do nothing\npath={}", path);
        }
    } catch (IOException e) {
        throw new UncheckedIOException("Failed to delete file " + path, e);
    }
}

private static void deleteFolder(Path path) {
    try (Stream\<Path\> walk = Files.walk(path)) {
        // sort in reverse so the directory itself comes after its child files
        for (Path child : walk.sorted(Comparator.reverseOrder()).toList()) {
            if (Files.deleteIfExists(child)) {
                LOGGER.debug("'{}' deleted", child);
            }
        }
    } catch (IOException e) {
        throw new UncheckedIOException("Failed to delete build folder", e);
    }
}

% java, http client, snippet

# Java native HTTP client.
HttpClient client = HttpClient.newBuilder().build();
HttpRequest request = HttpRequest.newBuilder()
    .uri(URI.create("https://horstmann.com/index.html"))
    .GET()
    .build();
HttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());
String result = response.body();

# Get data from HTTP response.
try (InputStream in = new URI("https://horstmann.com/index.html").toURL().openStream()) {
    byte[] bytes = in.readAllBytes();
    String result = new String(bytes);
    // or
    try (OutputStream out = Files.newOutputStream(path)) {
        in.transferTo(out);
    }
}
